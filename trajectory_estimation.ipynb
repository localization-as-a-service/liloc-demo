{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import utils.pointcloud as pointcloud\n",
    "import utils.registration as registration\n",
    "import utils.grid_search_rs_unopt as grid_search\n",
    "\n",
    "from utils.depth_camera import DepthCamera, DepthCameraParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data = np.load(\"temp/trajectory/local.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_ts = local_data[\"sequence_ts\"]\n",
    "local_t = local_data[\"local_t\"]\n",
    "local_pcds = local_data[\"local_pcds\"]\n",
    "num_frames = len(sequence_ts) - 1\n",
    "\n",
    "local_pcds = [pointcloud.make_pcd(local_pcds[i]) for i in range(num_frames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599, 599, 599)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames, len(local_pcds), len(local_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, num_frames, 20):\n",
    "    registration.view(local_pcds[i], local_pcds[i - 1], local_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_t = [np.identity(4)]\n",
    "\n",
    "for t in range(1, num_frames):\n",
    "    trajectory_t.append(np.dot(trajectory_t[t - 1], local_t[t]))\n",
    "    \n",
    "trajectory_pcd = []\n",
    "\n",
    "for i in range(num_frames):\n",
    "    pcd = copy.deepcopy(local_pcds[i])\n",
    "    pcd.transform(trajectory_t[i])\n",
    "    trajectory_pcd.append(pcd)\n",
    "\n",
    "trajectory_pcd = pointcloud.merge_pcds(trajectory_pcd, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud.view(trajectory_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_files = glob.glob(\"temp/trajectory/global_*.npz\")\n",
    "global_ts = [int(os.path.basename(f).split(\".\")[0].split(\"_\")[1]) for f in global_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_inds = []\n",
    "\n",
    "for i in range(len(global_ts)):\n",
    "    index = np.argwhere(sequence_ts == global_ts[i])[0][0]\n",
    "    global_inds.append(index)\n",
    "    # print(f\"Global {global_ts[i]} | Local {sequence_ts[index]} | Index {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Keypts: [6074, 28716]\tNo of matches: 1664\tFitness: 0.2740\tInlier RMSE: 0.0283\n",
      "1\n",
      "Keypts: [5997, 28822]\tNo of matches: 2053\tFitness: 0.3423\tInlier RMSE: 0.0279\n",
      "2\n",
      "Keypts: [5923, 29492]\tNo of matches: 2147\tFitness: 0.3625\tInlier RMSE: 0.0278\n",
      "3\n",
      "Keypts: [5557, 28699]\tNo of matches: 1848\tFitness: 0.3326\tInlier RMSE: 0.0273\n",
      "4\n",
      "Keypts: [5732, 29894]\tNo of matches: 2470\tFitness: 0.4309\tInlier RMSE: 0.0273\n",
      "5\n",
      "Keypts: [5547, 29316]\tNo of matches: 2483\tFitness: 0.4476\tInlier RMSE: 0.0278\n",
      "6\n",
      "Keypts: [4949, 28902]\tNo of matches: 3141\tFitness: 0.6347\tInlier RMSE: 0.0274\n",
      "7\n",
      "Keypts: [4359, 28716]\tNo of matches: 2944\tFitness: 0.6754\tInlier RMSE: 0.0273\n",
      "8\n",
      "Keypts: [3818, 28399]\tNo of matches: 2479\tFitness: 0.6493\tInlier RMSE: 0.0277\n",
      "9\n",
      "Keypts: [3287, 29985]\tNo of matches: 2569\tFitness: 0.7816\tInlier RMSE: 0.0276\n",
      "10\n",
      "Keypts: [3331, 28240]\tNo of matches: 2890\tFitness: 0.8676\tInlier RMSE: 0.0268\n",
      "11\n",
      "Keypts: [4071, 28595]\tNo of matches: 3058\tFitness: 0.7512\tInlier RMSE: 0.0277\n",
      "12\n",
      "Keypts: [4152, 28937]\tNo of matches: 3481\tFitness: 0.8384\tInlier RMSE: 0.0264\n",
      "13\n",
      "Keypts: [4002, 29050]\tNo of matches: 3473\tFitness: 0.8678\tInlier RMSE: 0.0267\n",
      "14\n",
      "Keypts: [3573, 30495]\tNo of matches: 3158\tFitness: 0.8839\tInlier RMSE: 0.0258\n",
      "15\n",
      "Keypts: [3519, 28625]\tNo of matches: 2846\tFitness: 0.8088\tInlier RMSE: 0.0277\n",
      "16\n",
      "Keypts: [3690, 28752]\tNo of matches: 3018\tFitness: 0.8179\tInlier RMSE: 0.0266\n",
      "17\n",
      "Keypts: [3956, 29032]\tNo of matches: 2656\tFitness: 0.6714\tInlier RMSE: 0.0271\n",
      "18\n",
      "Keypts: [4518, 28749]\tNo of matches: 2276\tFitness: 0.5038\tInlier RMSE: 0.0272\n",
      "19\n",
      "Keypts: [4997, 28762]\tNo of matches: 1597\tFitness: 0.3196\tInlier RMSE: 0.0276\n",
      "20\n",
      "Keypts: [5006, 28388]\tNo of matches: 2077\tFitness: 0.4149\tInlier RMSE: 0.0281\n",
      "21\n",
      "Keypts: [5335, 30396]\tNo of matches: 1735\tFitness: 0.3252\tInlier RMSE: 0.0279\n",
      "22\n",
      "Keypts: [4919, 29852]\tNo of matches: 2570\tFitness: 0.5225\tInlier RMSE: 0.0271\n",
      "23\n",
      "Keypts: [5456, 29550]\tNo of matches: 3482\tFitness: 0.6382\tInlier RMSE: 0.0274\n",
      "24\n",
      "Keypts: [5371, 29981]\tNo of matches: 2472\tFitness: 0.4602\tInlier RMSE: 0.0271\n"
     ]
    }
   ],
   "source": [
    "global_target_t = []\n",
    "\n",
    "for i in range(len(global_ts)):\n",
    "    global_data = np.load(f\"temp/trajectory/global_{global_ts[i]}.npz\", allow_pickle=True)\n",
    "    \n",
    "    source = global_data[\"source\"]\n",
    "    target = global_data[\"target\"]\n",
    "    \n",
    "    source_feat = global_data[\"source_feat\"]\n",
    "    target_feat = global_data[\"target_feat\"]\n",
    "    \n",
    "    source, target, result = grid_search.global_registration(source, source_feat, target, target_feat, cell_size=2, n_random=0.5, refine_enabled=True)\n",
    "    registration.describe(source, target, result)\n",
    "    \n",
    "    global_target_t.append(result.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.transform as transform\n",
    "\n",
    "def validate(T1, T2, T3, t1, t2, max_dist, max_rot):\n",
    "    c1 = transform.check(T3, np.dot(T2, t2), max_t=max_dist, max_r=max_rot)\n",
    "    c2 = transform.check(T3, np.dot(np.dot(T1, t1), t2), max_t=max_dist, max_r=max_rot)\n",
    "    c3 = transform.check(T2, np.dot(T1, t1), max_t=max_dist, max_r=max_rot)\n",
    "\n",
    "    print(f\"Check 1: {c1}, Check 2: {c2}, Check 3: {c3}\")\n",
    "    \n",
    "    # If two checks are true, the combination is wrong\n",
    "    if (c1 + c2 + c3) == 2:\n",
    "        raise Exception(\"Invalid combination\")\n",
    "\n",
    "    # If two checks are true, the combination is wrong\n",
    "    if (c1 + c2 + c3) == 0:\n",
    "        raise Exception(\"Invalid transformations\")\n",
    "\n",
    "    # If all the checks are valid, there is no need of correction\n",
    "    if c1 and c2 and c3:\n",
    "        print(\":: No need of correction.\")\n",
    "        return T1, T2, T3\n",
    "    \n",
    "    # If two checks are wrong, only one transformation needs correction\n",
    "    if c1:\n",
    "        # print(\":: Correcting Previous Transformation\")\n",
    "        T1 = np.dot(T2, transform.inv_transform(t1))\n",
    "    elif c2:\n",
    "        # print(\":: Correcting Current Transformation\")\n",
    "        T2 = np.dot(T1, t1)\n",
    "    else:\n",
    "        # print(\":: Correcting Future Transformation\")\n",
    "        T3 = np.dot(T2, t2)\n",
    "\n",
    "    return T1, T2, T3\n",
    "\n",
    "\n",
    "def merge_transformation_matrices(start_t, end_t, local_t):\n",
    "    local_ts = np.identity(4)\n",
    "\n",
    "    for t in range(start_t, end_t):\n",
    "        local_ts = np.dot(local_t[t + 1], local_ts)\n",
    "        \n",
    "    return local_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global registration verification: 2/25\n",
      "Total invalid global registrations: 0\n",
      "Validating and correcting global registrations.\n",
      "Check 1: True, Check 2: True, Check 3: True\n",
      ":: No need of correction.\n"
     ]
    }
   ],
   "source": [
    "global_t = [np.identity(4) for _ in range(num_frames)]\n",
    "\n",
    "found_correct_global = False\n",
    "found_correct_global_at = -1\n",
    "\n",
    "for t in range(len(global_inds)):\n",
    "    if t > 1 and not found_correct_global:\n",
    "        print(f\"Global registration verification: {t}/{len(global_inds)}\")\n",
    "        total = 0\n",
    "        for i in range(t, t - 3, -1):\n",
    "            if np.sum(global_target_t[i]) == 4:\n",
    "                total += 1\n",
    "                \n",
    "        print(f\"Total invalid global registrations: {total}\")        \n",
    "        if total > 1: continue\n",
    "        \n",
    "        print(f\"Validating and correcting global registrations.\")\n",
    "        try:\n",
    "            global_target_t[t - 2], global_target_t[t - 1], global_target_t[t] = validate(\n",
    "                global_target_t[t - 2], global_target_t[t - 1], global_target_t[t], \n",
    "                merge_transformation_matrices(global_inds[t - 2], global_inds[t - 1], local_t),\n",
    "                merge_transformation_matrices(global_inds[t - 1], global_inds[t], local_t),\n",
    "                max_rot=2, max_dist=0.1\n",
    "            )\n",
    "            found_correct_global = True\n",
    "            found_correct_global_at = t\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if found_correct_global:\n",
    "    global_t[global_inds[found_correct_global_at]] = global_target_t[found_correct_global_at]\n",
    "\n",
    "    for t in range(global_inds[found_correct_global_at] + 1, num_frames - 1):\n",
    "        global_t[t] = np.dot(global_t[t - 1], local_t[t])\n",
    "        \n",
    "    for t in range(global_inds[found_correct_global_at] - 1, -1, -1):\n",
    "        global_t[t] = np.dot(global_t[t + 1], transform.inv_transform(local_t[t + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, num_frames, 50):\n",
    "    registration.view(local_pcds[i], target, global_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_pcd = []\n",
    "\n",
    "for i in range(num_frames):\n",
    "    pcd = copy.deepcopy(local_pcds[i])\n",
    "    pcd.transform(global_t[i])\n",
    "    trajectory_pcd.append(pcd)\n",
    "\n",
    "trajectory_pcd = pointcloud.merge_pcds(trajectory_pcd, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalRegistrationVerification:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.local_t = []\n",
    "        self.global_t = []\n",
    "        self.sequence_ts = []\n",
    "        self.global_inds = []\n",
    "        self.global_pcds = []\n",
    "        self.local_pcds = []\n",
    "        self.global_target_t = []\n",
    "        self.found_correct_global = False\n",
    "        self.found_correct_global_at = -1\n",
    "        \n",
    "    def update_local(self, local_timestamp, local_pcd, local_transformation):\n",
    "        self.sequence_ts.append(local_timestamp)\n",
    "        self.local_t.append(local_transformation)\n",
    "        self.local_pcds.append(local_pcd)\n",
    "        \n",
    "        if self.found_correct_global:\n",
    "            self.global_t.append(np.dot(self.global_t[-1], local_transformation))\n",
    "        else:\n",
    "            self.global_t.append(np.identity(4))\n",
    "        \n",
    "    \n",
    "    def update_global(self, global_timestmap, global_pcd, global_transformation):\n",
    "        index = np.argwhere(np.array(self.sequence_ts) == global_timestmap).flatten()\n",
    "        print(index)\n",
    "        \n",
    "        if len(index) == 0:\n",
    "            print(f\"Timestamp {global_timestmap} not found in sequence.\")\n",
    "        else:\n",
    "            index = index[0]\n",
    "        \n",
    "        self.global_inds.append(index)\n",
    "        self.global_target_t.append(global_transformation)\n",
    "        self.global_pcds.append(global_pcd)\n",
    "        \n",
    "        if len(self.global_inds) > 2 and not self.found_correct_global:\n",
    "            self.verify()\n",
    "            \n",
    "    \n",
    "    def verify(self):\n",
    "        for t in range(len(self.global_inds)):\n",
    "            if t > 1:\n",
    "                print(f\"Global registration verification: {t}/{len(self.global_inds)}\")\n",
    "                total = 0\n",
    "                for i in range(t, t - 3, -1):\n",
    "                    if np.sum(self.global_target_t[i]) == 4:\n",
    "                        total += 1\n",
    "                        \n",
    "                print(f\"Total invalid global registrations: {total}\")        \n",
    "                if total > 1: return\n",
    "                \n",
    "                print(f\"Validating and correcting global registrations.\")\n",
    "                try:\n",
    "                    self.global_target_t[t - 2], self.global_target_t[t - 1], self.global_target_t[t] = validate(\n",
    "                        self.global_target_t[t - 2], self.global_target_t[t - 1], self.global_target_t[t], \n",
    "                        merge_transformation_matrices(self.global_inds[t - 2], self.global_inds[t - 1], self.local_t),\n",
    "                        merge_transformation_matrices(self.global_inds[t - 1], self.global_inds[t], self.local_t),\n",
    "                        max_rot=2, max_dist=0.1\n",
    "                    )\n",
    "                    self.found_correct_global = True\n",
    "                    self.found_correct_global_at = t\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception:\", e)\n",
    "                    return\n",
    "        \n",
    "        if self.found_correct_global:\n",
    "            self.global_t[self.global_inds[self.found_correct_global_at]] = self.global_target_t[self.found_correct_global_at]\n",
    "\n",
    "            for t in range(self.global_inds[self.found_correct_global_at] + 1, len(self.global_t)):\n",
    "                self.global_t[t] = np.dot(self.global_t[t - 1], self.local_t[t])\n",
    "                \n",
    "            for t in range(self.global_inds[self.found_correct_global_at] - 1, -1, -1):\n",
    "                self.global_t[t] = np.dot(self.global_t[t + 1], transform.inv_transform(self.local_t[t + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grv = GlobalRegistrationVerification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_frames):\n",
    "    grv.update_local(sequence_ts[i], local_pcds[i], local_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[25]\n",
      "[50]\n",
      "Global registration verification: 2/3\n",
      "Total invalid global registrations: 0\n",
      "Validating and correcting global registrations.\n",
      "Check 1: True, Check 2: True, Check 3: True\n",
      ":: No need of correction.\n",
      "[75]\n",
      "[100]\n",
      "[125]\n",
      "[150]\n",
      "[175]\n",
      "[200]\n",
      "[225]\n",
      "[249]\n",
      "[274]\n",
      "[299]\n",
      "[324]\n",
      "[349]\n",
      "[374]\n",
      "[399]\n",
      "[424]\n",
      "[449]\n",
      "[474]\n",
      "[499]\n",
      "[524]\n",
      "[549]\n",
      "[574]\n",
      "[]\n",
      "Timestamp 1685247662460 not found in sequence.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(global_ts)):\n",
    "    grv.update_global(global_ts[i], target, global_target_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, num_frames, 50):\n",
    "    registration.view(grv.local_pcds[i], grv.global_pcds[0], grv.global_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_files = glob.glob(\"temp/hololens/data_*.npz\")\n",
    "\n",
    "sequence_ts = np.array([int(os.path.basename(f).split(\"_\")[1].split(\".\")[0]) for f in depth_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sequence_ts[10]\n",
    "\n",
    "depth_file = f\"temp/hololens/data_{t}.npz\"\n",
    "\n",
    "depth_data = np.load(depth_file)\n",
    "\n",
    "depth = depth_data[\"depth\"]\n",
    "pose = depth_data[\"pose\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fx: 174.93409729003906, fy: 179.96331787109375, cx: 168.45681762695312, cy: 171.1561737060547\n",
    "width: 320, height: 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params = DepthCameraParams(\"metadata/hololens.json\")\n",
    "depth_camera = DepthCamera(camera_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcd = depth_camera.depth_image_to_point_cloud(depth)\n",
    "pcd = pointcloud.make_pcd(depth.reshape(-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_pcds = []\n",
    "global_t = []\n",
    "local_t = [np.identity(4)]\n",
    "\n",
    "for t in sequence_ts[:5]:\n",
    "    depth_file = f\"temp/hololens/data_{t}.npz\"\n",
    "\n",
    "    depth_data = np.load(depth_file)\n",
    "\n",
    "    depth = depth_data[\"depth\"]\n",
    "    pose = depth_data[\"pose\"].T\n",
    "    \n",
    "    pcd = pointcloud.make_pcd(depth.reshape(-1, 3))\n",
    "    # pcd.transform(pose)\n",
    "    \n",
    "    local_pcds.append(pcd)\n",
    "    global_t.append(pose)\n",
    "    \n",
    "    if len(local_pcds) > 1:\n",
    "        t = np.dot(transform.inv_transform(global_t[-2]), global_t[-1])\n",
    "        local_t.append(t)\n",
    "    \n",
    "    \n",
    "# local_pcds = pointcloud.merge_pcds(local_pcds, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    print(i, i - 1)\n",
    "    t = np.dot(transform.inv_transform(global_t[i - 1]), global_t[i])\n",
    "    registration.view(local_pcds[i], local_pcds[i - 1], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(local_pcds)):\n",
    "    local_pcds[i].transform(local_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "open3d.visualization.draw_geometries(local_pcds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = len(local_pcds)\n",
    "\n",
    "trajectory_t = [np.identity(4)]\n",
    "\n",
    "for t in range(1, num_frames):\n",
    "    trajectory_t.append(np.dot(trajectory_t[t - 1], local_t[t]))\n",
    "    \n",
    "trajectory_pcd = []\n",
    "\n",
    "for i in range(num_frames):\n",
    "    pcd = copy.deepcopy(local_pcds[i])\n",
    "    pcd.transform(trajectory_t[i])\n",
    "    trajectory_pcd.append(pcd)\n",
    "\n",
    "trajectory_pcd = pointcloud.merge_pcds(trajectory_pcd, 0.05)\n",
    "\n",
    "open3d.visualization.draw_geometries([trajectory_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
